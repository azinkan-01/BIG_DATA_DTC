{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Movie Recommendation Service - Ripe-Pumpkin \n",
    "### Source: https://www.codementor.io/spark/tutorial/building-a-recommender-with-apache-spark-python-example-app-part1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a SparkContext configured for local mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File download \n",
    "Full: 27,753,444 ratings applied to 58,098 movies by 283,228 users. Last updated 2019-12-03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "# small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download location(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datasets_path = os.path.join('/home/jovyan', 'work')\n",
    "\n",
    "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
    "# small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "complete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)\n",
    "# small_f = urllib.request.urlretrieve (small_dataset_url, small_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    " \n",
    "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "    \n",
    "# with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "#     z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and parsing datasets\n",
    "Now we are ready to read in each of the files and create an RDD consisting of parsed lines. \n",
    "\n",
    "Each line in the ratings dataset (ratings.csv) is formatted as: \n",
    "+ userId,movieId,rating,timestamp \n",
    "\n",
    "Each line in the movies (movies.csv) dataset is formatted as:\n",
    "+ movieId,title,genres \n",
    "\n",
    "### We will now load the raw data, filter out the header, and parse the data into a new RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27753444 recommendations in the complete dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 307, 3.5), (1, 1257, 4.5), (1, 2986, 2.5)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_ratings_file = os.path.join(datasets_path, 'ml-latest', 'ratings.csv')\n",
    "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
    "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n",
    "# Parse\n",
    "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "\n",
    "print ('There are {} recommendations in the complete dataset'.format(complete_ratings_data.count()))\n",
    "complete_ratings_data = complete_ratings_data.sample(False, 0.10,42)\n",
    "complete_ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58098 movies in the complete dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'Toy Story (1995)', 'Adventure|Animation|Children|Comedy|Fantasy'),\n",
       " (4, 'Waiting to Exhale (1995)', 'Comedy|Drama|Romance'),\n",
       " (11, '\"American President', ' The (1995)\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the small dataset file\n",
    "complete_movies_file = os.path.join(datasets_path, 'ml-latest', 'movies.csv')\n",
    "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
    "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "print ('There are {} movies in the complete dataset'.format(complete_movies_titles.count()))\n",
    "complete_movies_data = complete_movies_data.sample(False, 0.10,42)\n",
    "complete_movies_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pandas and read as DF\n",
    "###### This was just to get a look at quick descriptive variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read it in as a data frame\n",
    "movies_df = pd.read_csv(complete_movies_file)\n",
    "ratings_df = pd.read_csv(complete_ratings_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show a sample of the movie data\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1091</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1256677471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1257</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1449</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      307     3.5  1256677221\n",
       "1       1      481     3.5  1256677456\n",
       "2       1     1091     1.5  1256677471\n",
       "3       1     1257     4.5  1256677460\n",
       "4       1     1449     4.5  1256677264"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show sample of the ratings data\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the ratings df is 27753444\n",
      "length of the movies df is 58098\n",
      "Number or unique users that responded with ratings         userId\n",
      "rating        \n",
      "0.5      64259\n",
      "1.0     135726\n",
      "1.5      73710\n",
      "2.0     189352\n",
      "2.5     113452\n",
      "3.0     248815\n",
      "3.5     143890\n",
      "4.0     263790\n",
      "4.5     139104\n",
      "5.0     241003\n",
      "Average rating collected from data set is rating    3.530445\n",
      "dtype: float64\n",
      "There are userId    283228\n",
      "dtype: int64 unique users that have contibuted to this rating pool\n"
     ]
    }
   ],
   "source": [
    "# Length of each df\n",
    "print(\"length of the ratings df is {}\".format(len(ratings_df)))\n",
    "print(\"length of the movies df is {}\".format(len(movies_df)))\n",
    "\n",
    "unique_rating = ratings_df.groupby('rating').agg({'userId': 'nunique'})\n",
    "print(\"Number or unique users that responded with ratings {}\".format(unique_rating))\n",
    "\n",
    "average_rating = ratings_df.agg({'rating':'mean'})\n",
    "print(\"Average rating collected from data set is {}\".format(average_rating))\n",
    "\n",
    "num_unique_users = ratings_df.agg({'userId':'nunique'})\n",
    "print(\"There are {} unique users that have contibuted to this rating pool\".format(num_unique_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for ratings ranged from                        time_stamp\n",
      "max 1970-01-01 00:00:01.537945149\n",
      "min 1970-01-01 00:00:00.789652004\n"
     ]
    }
   ],
   "source": [
    "# Convert to time stamp \n",
    "time_df = ratings_df\n",
    "time_df['time_stamp'] = pd.to_datetime(ratings_df['timestamp'])\n",
    "\n",
    "# Pick out the max and min date range\n",
    "range_res = time_df.agg({'time_stamp':['max', 'min']})\n",
    "print(\"Time for ratings ranged from {}\".format(range_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58098.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>111919.516197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59862.660956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>72437.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>126549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>161449.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>193886.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             movieId\n",
       "count   58098.000000\n",
       "mean   111919.516197\n",
       "std     59862.660956\n",
       "min         1.000000\n",
       "25%     72437.750000\n",
       "50%    126549.000000\n",
       "75%    161449.500000\n",
       "max    193886.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discribe movies df\n",
    "movies_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.775344e+07</td>\n",
       "      <td>2.775344e+07</td>\n",
       "      <td>2.775344e+07</td>\n",
       "      <td>2.775344e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.419420e+05</td>\n",
       "      <td>1.848800e+04</td>\n",
       "      <td>3.530445e+00</td>\n",
       "      <td>1.193122e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.170740e+04</td>\n",
       "      <td>3.510263e+04</td>\n",
       "      <td>1.066353e+00</td>\n",
       "      <td>2.160482e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>7.896520e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.117600e+04</td>\n",
       "      <td>1.097000e+03</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>9.986053e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.420220e+05</td>\n",
       "      <td>2.716000e+03</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>1.174256e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.124590e+05</td>\n",
       "      <td>7.150000e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.422744e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.832280e+05</td>\n",
       "      <td>1.938860e+05</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.537945e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId       movieId        rating     timestamp\n",
       "count  2.775344e+07  2.775344e+07  2.775344e+07  2.775344e+07\n",
       "mean   1.419420e+05  1.848800e+04  3.530445e+00  1.193122e+09\n",
       "std    8.170740e+04  3.510263e+04  1.066353e+00  2.160482e+08\n",
       "min    1.000000e+00  1.000000e+00  5.000000e-01  7.896520e+08\n",
       "25%    7.117600e+04  1.097000e+03  3.000000e+00  9.986053e+08\n",
       "50%    1.420220e+05  2.716000e+03  3.500000e+00  1.174256e+09\n",
       "75%    2.124590e+05  7.150000e+03  4.000000e+00  1.422744e+09\n",
       "max    2.832280e+05  1.938860e+05  5.000000e+00  1.537945e+09"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 442388.,  886233.,  441354., 1850627., 1373419., 5515668.,\n",
       "        3404360., 7394710., 2373550., 4071135.]),\n",
       " array([0.5 , 0.95, 1.4 , 1.85, 2.3 , 2.75, 3.2 , 3.65, 4.1 , 4.55, 5.  ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEDCAYAAAAcI05xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMoUlEQVR4nO3dUYyldX3G8efpulS7YEncU0Nc0jENrjEYAU9oWgxpMZilS9CLtoGoSQ1xbtRA2mrW3nm3vTH2wjaZIG2NCFGBpmFblMQ1lAYWzyyLsrvQWBzjEu0cRALrRSn49OKcYWfGs8w7ct7z/nbm+0kmO+ecl3N+vBffvPvf932PkwgAUNdvdD0AAOC1EWoAKI5QA0BxhBoAiiPUAFAcoQaA4loLte3bbS/bfqLh9n9u+4Tt47a/2tZcAHCucVvnUdu+WtJpSV9OcukG214i6WuSrknyc9u/k2S5lcEA4BzT2hF1kgclPbf6Odu/Z/t+24u2/8P2O8cvfVzSF5P8fPzfEmkAGJv1GvWCpE8lea+kv5b09+Pn3yHpHbb/0/YjtvfNeC4AKOsNs/og2+dL+kNJX7e98vRvrprjEkl/JGmPpAdtvzvJ87OaDwCqmlmoNTp6fz7JZRNeOyXpSJL/k/RD2/+lUbi/O8P5AKCkmS19JHlBowj/mSR55D3jl/9Fo6Np2d6t0VLI07OaDQAqa/P0vDslPSxpr+1Ttm+W9GFJN9t+XNJxSR8cb/5NST+zfULSYUmfTvKztmYDgHNJa6fnAQCmgysTAaC4Vv4xcffu3Zmbm2vjrQFgS1pcXHw2SW/Sa62Eem5uToPBoI23BoAtyfaPzvYaSx8AUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQ3CzvRw2gA3MHDnXyuUsH93fyuVsRR9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcRuG2vZe28dW/bxg+9YZzAYAUIMLXpI8JekySbK9Q9Izku5tdywAwIrNLn28X9J/Jznrd3sBAKZrs6G+UdKdk16wPW97YHswHA5f/2QAAEmbCLXt8yTdIOnrk15PspCkn6Tf6038xnMAwK9hM0fU10k6muR/2hoGAPCrNhPqm3SWZQ8AQHsahdr2LknXSrqn3XEAAOs1uh91kl9IekvLswAAJuDKRAAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAimv65bYX2v6G7Sdtn7T9B20PBgAYafTltpL+TtL9Sf7U9nmSfqvFmQAAq2wYatu/LelqSX8hSUlekvRSu2MBAFY0Wfp4u6ShpH+0/Zjt22zvWr+R7XnbA9uD4XA49UEBYLtqEuo3SLpC0j8kuVzSLyQdWL9RkoUk/ST9Xq835TEBYPtqEupTkk4lOTJ+/A2Nwg0AmIENQ53kp5J+bHvv+Kn3SzrR6lQAgFc1PevjU5LuGJ/x8bSkj7U3EgBgtUahTnJMUr/dUQAAk3BlIgAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFBc0wtegC1h7sChTj536eD+Tj4XWwNH1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABTX6F4ftpckvSjpFUkvJ+H7EwFgRjZzU6Y/TvJsa5MAACZi6QMAimsa6kj6lu1F2/OTNrA9b3tgezAcDqc3IQBsc01D/b4kV0i6TtInbF+9foMkC0n6Sfq9Xm+qQwLAdtYo1EmeGf+5LOleSVe2ORQA4IwNQ217l+0LVn6X9AFJT7Q9GABgpMlZH2+VdK/tle2/muT+VqcCALxqw1AneVrSe2YwCwBgAk7PA4DiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGguMahtr3D9mO272tzIADAWk2+hXzFLZJOSnpzS7MAwFTMHTjUyecuHdzfyvs2OqK2vUfSfkm3tTIFAOCsmi59fEHSZyT98mwb2J63PbA9GA6H05gNAKAGobZ9vaTlJIuvtV2ShST9JP1erze1AQFgu2tyRH2VpBtsL0m6S9I1tr/S6lQAgFdtGOokn02yJ8mcpBslfTvJR1qfDAAgifOoAaC8zZyepyTfkfSdViYBAEzEETUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoLhNXUIO4NfT1TeOYGvgiBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHEbhtr2G20/avtx28dtf24WgwEARppcmfi/kq5Jctr2TkkP2f73JI+0PBsAQA1CnSSSTo8f7hz/pM2hAABnNFqjtr3D9jFJy5IeSHJkwjbztge2B8PhcMpjAsD21SjUSV5JcpmkPZKutH3phG0WkvST9Hu93pTHBIDta1NnfSR5XtJhSftamQYA8CuanPXRs33h+Pc3SbpW0pMtzwUAGGty1sdFkv7Z9g6Nwv61JPe1OxYAYEWTsz6+J+nyGcwCAJiAKxMBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAorslNmQBg0+YOHOp6hC2DI2oAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGguCbfQn6x7cO2T9g+bvuWWQwGABhpcsHLy5L+KslR2xdIWrT9QJITLc8GAFCDI+okP0lydPz7i5JOSnpb24MBAEY2tUZte07S5ZKOTHht3vbA9mA4HE5pPABA41DbPl/S3ZJuTfLC+teTLCTpJ+n3er1pzggA21qjUNveqVGk70hyT7sjAQBWa3LWhyV9SdLJJJ9vfyQAwGpNzvq4StJHJX3f9rHxc3+T5N9amwoz0eVtKJcO7u/ss4FzzYahTvKQJM9gFgDABFyZCADFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHFNbsoETF2XN4QCzjUcUQNAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFNfkW8tttL9t+YhYDAQDWanJE/U+S9rU8BwDgLDYMdZIHJT03g1kAABNMbY3a9rztge3BcDic1tsCwLY3tVAnWUjST9Lv9XrTelsA2PY46wMAiuPueWNd3s1t6eD+zj4bQH1NTs+7U9LDkvbaPmX75vbHAgCs2PCIOslNsxgEADAZa9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQXLl7fXR5z42ubMf/ZwDNcUQNAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxTUKte19tp+y/QPbB9oeCgBwRpNvId8h6YuSrpP0Lkk32X5X24MBAEaaHFFfKekHSZ5O8pKkuyR9sN2xAAArmtyU6W2Sfrzq8SlJv79+I9vzkubHD0/bfur1j9ep3ZKe7XqIItgXa7E/1mJ/jPlvX9e++N2zvTC1u+clWZC0MK3365rtQZJ+13NUwL5Yi/2xFvvjjLb2RZOlj2ckXbzq8Z7xcwCAGWgS6u9KusT2222fJ+lGSf/a7lgAgBUbLn0kedn2JyV9U9IOSbcnOd76ZN3bMss4U8C+WIv9sRb744xW9oWTtPG+AIAp4cpEACiOUANAcYR6Hdu32162/UTXs3TN9sW2D9s+Yfu47Vu6nqkrtt9o+1Hbj4/3xee6nqkC2ztsP2b7vq5n6ZrtJdvft33M9mCq780a9Vq2r5Z0WtKXk1za9Txdsn2RpIuSHLV9gaRFSR9KcqLj0WbOtiXtSnLa9k5JD0m6JckjHY/WKdt/Kakv6c1Jru96ni7ZXpLUTzL1i384ol4nyYOSnut6jgqS/CTJ0fHvL0o6qdGVqttORk6PH+4c/2zroxzbeyTtl3Rb17NsdYQajdiek3S5pCMdj9KZ8V/zj0lalvRAkm27L8a+IOkzkn7Z8RxVRNK3bC+Ob6kxNYQaG7J9vqS7Jd2a5IWu5+lKkleSXKbR1blX2t62S2O2r5e0nGSx61kKeV+SKzS60+gnxsuoU0Go8ZrG67F3S7ojyT1dz1NBkuclHZa0r+NRunSVpBvG67J3SbrG9le6HalbSZ4Z/7ks6V6N7jw6FYQaZzX+B7QvSTqZ5PNdz9Ml2z3bF45/f5OkayU92elQHUry2SR7ksxpdFuJbyf5SMdjdcb2rvE/uMv2LkkfkDS1M8cI9Tq275T0sKS9tk/ZvrnrmTp0laSPanS0dGz88yddD9WRiyQdtv09je5/80CSbX9KGl71VkkP2X5c0qOSDiW5f1pvzul5AFAcR9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcf8POkfZlrZn2qEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(ratings_df['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to RDD work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "In Collaborative filtering we make predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption is that if a user A has the same opinion as a user B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a user chosen randomly. \n",
    "\n",
    "At first, people rate different items (like videos, images, games). Then, the system makes predictions about a user's rating for an item not rated yet. The new predictions are built upon the existing ratings of other users with similar ratings with the active user. In the image, the system predicts that the user will not like the video.\n",
    "\n",
    "Spark MLlib library for Machine Learning provides a Collaborative Filtering implementation by using Alternating Least Squares. The implementation in MLlib has the following parameters:\n",
    "\n",
    "+ numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).\n",
    "+ rank is the number of latent factors in the model.\n",
    "+ iterations is the number of iterations to run.\n",
    "+ lambda specifies the regularization parameter in ALS.\n",
    "+ implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\n",
    "+ alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting ALS parameters using 10% of the full dataset\n",
    "In order to determine the best ALS parameters, we need first to split it into train, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source uses see=0L, which is the previous version of python (2.x)\n",
    "# 0L should be written as 0 from now on\n",
    "training_RDD, validation_RDD, test_RDD = complete_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.9789952472834301\n",
      "For rank 8 the RMSE is 0.9936466156402521\n",
      "For rank 12 the RMSE is 0.9980974326180787\n",
      "The best model was trained with rank 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print ('For rank {} the RMSE is {}'.format(rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print ('The best model was trained with rank {}'.format(best_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((269599, 593), 3.7484784276673055),\n",
       " ((279323, 1101), 3.7631367425494306),\n",
       " ((279323, 2710), 2.5732641571948576)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at our new predictions alone\n",
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((4, 170), (3.0, 3.6398973205389753)),\n",
       " ((23, 1231), (3.0, 4.161464165987251)),\n",
       " ((31, 2791), (4.0, 3.798922728627975))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at our predictions relitive to the observed value\n",
    "rates_and_preds.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally we test the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.9821325201162072\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print ('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the complete dataset to build the final model\n",
    "Due to the limitations of virtual machine, we keep using the partial dataset instead of complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58098 movies in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "complete_movies_file = os.path.join(datasets_path, 'ml-latest', 'movies.csv')\n",
    "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
    "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "    \n",
    "print (\"There are %s movies in the complete dataset\" % (complete_movies_titles.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now we are ready to trai the recomender model\n",
    "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0)\n",
    "\n",
    "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
    "                           iterations=iterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.958582993083312\n"
     ]
    }
   ],
   "source": [
    "# Now we test on our testing set\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print ('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to make recommendations\n",
    "Although we aim at building an online movie recommender, now that we know how to have our recommender model ready, we can give it a try providing some movie recommendations. This will help us coding the recommending engine later on when building the web service, and will explain how to use the model in any other circumstances.\n",
    "\n",
    "When using collaborative filtering, getting recommendations is not as simple as predicting for the new entries using a previously generated model. Instead, we need to train again the model but including the new user preferences in order to compare them with other users in the dataset. That is, the recommender needs to be trained every time we have new user ratings (although a single model can be used by multiple users of course!). This makes the process expensive, and it is one of the reasons why scalability is a problem (and Spark a solution!). Once we have our model trained, we can reuse it to obtain top recomendations for a given user or an individual rating for a particular movie. These are less costly operations than training the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### let's first load the movies complete file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58098 movies in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "complete_movies_file = os.path.join(datasets_path, 'ml-latest', 'movies.csv')\n",
    "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
    "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "    \n",
    "print (\"There are %s movies in the complete dataset\" % (complete_movies_titles.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we want to do, is give recommendations of movies with a certain minimum number of ratings. For that, we need to count the number of ratings per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new user ratings\n",
    "Now we need to rate some movies for the new user. We will put them in a new RDD and we will use the user ID 0, that is not assigned in the MovieLens dataset. Check the dataset movies file for ID to Tittle assignment (so you know what movies are you actually rating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 260, 4), (0, 1, 3), (0, 16, 3), (0, 25, 4), (0, 32, 4), (0, 335, 1), (0, 379, 1), (0, 296, 3), (0, 858, 5), (0, 50, 4)]\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "\n",
    "# ###################################################\n",
    "# Keep the userID, but Replace movieID, rating, title\n",
    "# ###################################################\n",
    "\n",
    "# Find 10 movies you have watched in the past\n",
    "# Put your OWN ratings\n",
    "\n",
    "new_user_ratings = [\n",
    "     (0,260,4), # Star Wars (1977)\n",
    "     (0,1,3), # Toy Story (1995)\n",
    "     (0,16,3), # Casino (1995)\n",
    "     (0,25,4), # Leaving Las Vegas (1995)\n",
    "     (0,32,4), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
    "     (0,335,1), # Flintstones, The (1994)\n",
    "     (0,379,1), # Timecop (1994)\n",
    "     (0,296,3), # Pulp Fiction (1994)\n",
    "     (0,858,5), # Godfather, The (1972)\n",
    "     (0,50,4) # Usual Suspects, The (1995)\n",
    "    ]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print ('New user ratings: {}'.format(new_user_ratings_RDD.take(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add them to the data we will use to train our recommender model. We use Spark's union() transformation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_70 = complete_ratings_data.sample(False, 0.7, 42)\n",
    "# complete_data_with_new_ratings_RDD = sample_70.union(new_user_ratings_RDD)\n",
    "\n",
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we train the ALS model using all the parameters we selected before (when using the small dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model trained in 47.144 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed,\n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print ('New model trained in {} seconds'.format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting top recommendations\n",
    "Let's now get some recommendations! For that we will get an RDD with all the movies the new user hasn't rated yet. We will them together with the model to predict ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our recommendations ready. Now we can print out the 25 movies with the highest predicted ratings. And join them with the movies RDD to get the titles, and ratings count in order to get movies with a minimum number of counts. First we will do the join and see what does the result looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6216,\n",
       "  ((3.076647358067289, 'Nowhere in Africa (Nirgendwo in Afrika) (2001)'), 73)),\n",
       " (167832, ((3.140788473425439, 'The Invisible Guest (2016)'), 25)),\n",
       " (80808, ((2.4415489706842823, '\"Night Strangler'), 2))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to flat this down a bit in order to have (Title, Rating, Ratings Count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, get the highest rated recommendations for the new user, filtering out movies with less than 25 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended movies (with more than 25 reviews):\n",
      "('Eddie Izzard: Dress to Kill (1999)', 4.580889503989454, 48)\n",
      "('\"Honest Liar', 4.527483288603637, 26)\n",
      "('Louis C.K.: Live at the Beacon Theater (2011)', 4.43691630007984, 183)\n",
      "('Heart of a Dog (Sobachye serdtse) (1988)', 4.394862160617029, 76)\n",
      "('American Pimp (1999)', 4.288118540832867, 33)\n",
      "('\"Room', 4.244631122510164, 62)\n",
      "('As it is in Heaven (Så som i himmelen) (2004)', 4.242746637250008, 30)\n",
      "('Louis C.K.: Hilarious (2010)', 4.240945929491364, 172)\n",
      "('Over the Garden Wall (2013)', 4.200196279456925, 31)\n",
      "(\"Vampire's Kiss (1989)\", 4.165583278820783, 26)\n",
      "('Roger & Me (1989)', 4.142298831653164, 830)\n",
      "('\"Night Porter', 4.1387160676152455, 33)\n",
      "('Tekkonkinkreet (Tekkon kinkurîto) (2006)', 4.133562668669271, 43)\n",
      "('High Art (1998)', 4.109954373531242, 108)\n",
      "('Heima (2007)', 4.1022903421916315, 29)\n"
     ]
    }
   ],
   "source": [
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 25 reviews):\\n{}'.format('\\n'.join(map(str, top_movies))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting individual ratings\n",
    "Another useful usecase is getting the predicted rating for a particular movie for a given user. The process is similar to the previous retreival of top recommendations but, instead of using predcitAll with every single movie the user hasn't rated yet, we will just pass the method a single entry with the movie we want to predict the rating for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=0, product=116688, rating=0.3524519520761742)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\n",
    "individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "individual_movie_rating_RDD.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario #1 \n",
    "### 10 movies I have watched w/ more than 25 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 2657, 2), (0, 2944, 2), (0, 2992, 1), (0, 103228, 2), (0, 104076, 3), (0, 356, 5), (0, 2959, 5), (0, 54256, 5), (0, 260, 4), (0, 1, 3)]\n",
      "New model trained in 47.192 seconds\n",
      "TOP recommended movies (with more than 25 reviews):\n",
      "('\"Legend of 1900', 4.661771829673427, 76)\n",
      "('Night and Fog (Nuit et brouillard) (1955)', 4.621192223462998, 48)\n",
      "('Doctor Who: The Time of the Doctor (2013)', 4.615535026860542, 51)\n",
      "('Dolls (2002)', 4.5597466634022155, 41)\n",
      "('7 Plus Seven (1970)', 4.521651983767111, 29)\n",
      "('\"Bang', 4.487954904860565, 57)\n",
      "(\"Dr. Horrible's Sing-Along Blog (2008)\", 4.4560534744584, 469)\n",
      "('Louis C.K. 2017 (2017)', 4.444106365718653, 25)\n",
      "('\"Day of the Doctor', 4.441906116893037, 135)\n",
      "('Planet Earth II (2016)', 4.426150026470964, 98)\n",
      "('Zeitgeist: Addendum (2008)', 4.4133401811430115, 38)\n",
      "('Ricky Gervais Live: Animals (2003)', 4.403559787363946, 41)\n",
      "('\"Ultimate Gift', 4.3610936350556155, 26)\n",
      "('Peaceful Warrior (2006)', 4.357752176975282, 30)\n",
      "('Take This Waltz (2011)', 4.350569888301074, 25)\n"
     ]
    }
   ],
   "source": [
    "# The format of each line is (userID, movieID, rating)\n",
    "\n",
    "# S1 - 10 movies I have watched.\n",
    "\n",
    "new_user_ratings = [\n",
    "     (0,2657,2), # Rocky Horror Picture Show\n",
    "     (0,2944,2), # Dirty Dozen, The (1967)\n",
    "     (0,2992,1), # Rawhead Rex (1986)\n",
    "     (0,103228,2), # Pacific Rim (2013)\n",
    "     (0,104076,3), # Smurfs 2, The (2013)\n",
    "     (0,356,5), # Forrest Gump (1994)\n",
    "     (0,2959,5), # Fight Club (1999)\n",
    "     (0,54256,5), # Hot Rod (2007)\n",
    "     (0,260,4), # Star Wars (1977)\n",
    "     (0,1,3), # Toy Story (1995)\n",
    "    ]\n",
    "\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print ('New user ratings: {}'.format(new_user_ratings_RDD.take(10)))\n",
    "\n",
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)\n",
    "\n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed,\n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print ('New model trained in {} seconds'.format(round(tt,3)))\n",
    "\n",
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "\n",
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)\n",
    "\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "\n",
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 25 reviews):\\n{}'.format('\\n'.join(map(str, top_movies))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario #2\n",
    "### 10 movies I have watched w/ more than 100 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 2657, 2), (0, 2944, 2), (0, 2992, 1), (0, 103228, 2), (0, 104076, 3), (0, 356, 5), (0, 2959, 5), (0, 54256, 5), (0, 260, 4), (0, 1, 3)]\n",
      "New model trained in 46.855 seconds\n",
      "TOP recommended movies (with more than 25 reviews):\n",
      "(\"Dr. Horrible's Sing-Along Blog (2008)\", 4.4560534744584, 469)\n",
      "('\"Day of the Doctor', 4.441906116893037, 135)\n",
      "('\"Man Without a Past', 4.30368824927934, 124)\n",
      "('Your Name. (2016)', 4.28896204871193, 125)\n",
      "('Planet Earth (2006)', 4.287513408914464, 163)\n",
      "('Interstellar (2014)', 4.2816202497674, 2310)\n",
      "('Mad Max: Fury Road (2015)', 4.226180483260716, 1276)\n",
      "('Fight Club (1999)', 4.216114907018548, 6566)\n",
      "('\"Batman: The Dark Knight Returns', 4.20620518798669, 128)\n",
      "('Forrest Gump (1994)', 4.196212789266365, 9779)\n",
      "('Paperman (2012)', 4.183828127060789, 232)\n",
      "('\"Celebration', 4.183235923209189, 263)\n",
      "('Battlestar Galactica (2003)', 4.169344867729478, 478)\n",
      "('Princess Mononoke (Mononoke-hime) (1997)', 4.16134013614073, 1402)\n",
      "('\"Texas Chainsaw Massacre', 4.159898299153927, 356)\n"
     ]
    }
   ],
   "source": [
    "# The format of each line is (userID, movieID, rating)\n",
    "\n",
    "# S2 - 10 movies I have watched.\n",
    "\n",
    "new_user_ratings = [\n",
    "     (0,2657,2), # Rocky Horror Picture Show\n",
    "     (0,2944,2), # Dirty Dozen, The (1967)\n",
    "     (0,2992,1), # Rawhead Rex (1986)\n",
    "     (0,103228,2), # Pacific Rim (2013)\n",
    "     (0,104076,3), # Smurfs 2, The (2013)\n",
    "     (0,356,5), # Forrest Gump (1994)\n",
    "     (0,2959,5), # Fight Club (1999)\n",
    "     (0,54256,5), # Hot Rod (2007)\n",
    "     (0,260,4), # Star Wars (1977)\n",
    "     (0,1,3), # Toy Story (1995)\n",
    "    ]\n",
    "\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print ('New user ratings: {}'.format(new_user_ratings_RDD.take(10)))\n",
    "\n",
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)\n",
    "\n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed,\n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print ('New model trained in {} seconds'.format(round(tt,3)))\n",
    "\n",
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "\n",
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)\n",
    "\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "\n",
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=100).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 25 reviews):\\n{}'.format('\\n'.join(map(str, top_movies))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario #3\n",
    "### 10 movies my roomate has watched w/ more than 25 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 260, 3), (0, 1, 4), (0, 356, 5), (0, 2959, 5), (0, 3033, 1), (0, 3100, 2), (0, 3404, 2), (0, 3190, 2), (0, 54256, 5), (0, 3107, 3)]\n",
      "New model trained in 46.688 seconds\n",
      "TOP recommended movies (with more than 25 reviews):\n",
      "('Night and Fog (Nuit et brouillard) (1955)', 4.533164367663325, 48)\n",
      "('Planet Earth II (2016)', 4.507393621817151, 98)\n",
      "('Planet Earth (2006)', 4.47022538344639, 163)\n",
      "('Ugetsu (Ugetsu monogatari) (1953)', 4.465737547791676, 43)\n",
      "('\"Decalogue', 4.451606921398522, 46)\n",
      "('7 Plus Seven (1970)', 4.449614648879461, 29)\n",
      "('Sunless (Sans Soleil) (1983)', 4.443270293577186, 41)\n",
      "('John Mulaney: New In Town (2012)', 4.443055707830247, 28)\n",
      "('Harakiri (Seppuku) (1962)', 4.437935194246407, 61)\n",
      "('\"You', 4.433031497483299, 32)\n",
      "('Doctor Who: The Time of the Doctor (2013)', 4.383631441267042, 51)\n",
      "('\"Celebration', 4.37739982926756, 263)\n",
      "('Wolf Children (Okami kodomo no ame to yuki) (2012)', 4.373658289606723, 44)\n",
      "('Dolls (2002)', 4.339780689371096, 41)\n",
      "('\"Rome', 4.334438962176691, 49)\n"
     ]
    }
   ],
   "source": [
    "# The format of each line is (userID, movieID, rating)\n",
    "\n",
    "# S3 - 10 movies you have watched with ratings 3 or higher. \n",
    "new_user_ratings = [\n",
    "     (0,260,3), # Star Wars (1977)\n",
    "     (0,1,4), # Toy Story (1995)\n",
    "     (0,356,5), # Forrest Gump (1994)\n",
    "     (0,2959,5), # Fight Club (1999)\n",
    "     (0,3033,1), # Spaceballs (1987)\n",
    "     (0,3100,2), # River Runs Through It\n",
    "     (0,3404,2), # Titanic (1953)\n",
    "     (0,3190,2), # Supernova (2000)\n",
    "     (0,54256,5), # Hot Rod (2007)\n",
    "     (0,3107,3) # Backdraft (1991)\n",
    "    ]\n",
    "\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print ('New user ratings: {}'.format(new_user_ratings_RDD.take(10)))\n",
    "\n",
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)\n",
    "\n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed,\n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print ('New model trained in {} seconds'.format(round(tt,3)))\n",
    "\n",
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "\n",
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)\n",
    "\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "\n",
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 25 reviews):\\n{}'.format('\\n'.join(map(str, top_movies))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario #4\n",
    "### 10 movies my roomate has watched w/ more than 100 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 260, 3), (0, 1, 4), (0, 356, 5), (0, 2959, 5), (0, 3033, 1), (0, 3100, 2), (0, 3404, 2), (0, 3190, 2), (0, 54256, 5), (0, 3107, 3)]\n",
      "New model trained in 46.58 seconds\n",
      "TOP recommended movies (with more than 25 reviews):\n",
      "('Planet Earth (2006)', 4.47022538344639, 163)\n",
      "('\"Celebration', 4.37739982926756, 263)\n",
      "('Persona (1966)', 4.319460257846302, 189)\n",
      "('Andrei Rublev (Andrey Rublyov) (1969)', 4.304797146909401, 114)\n",
      "('Louis C.K.: Chewed Up (2008)', 4.266116878775293, 162)\n",
      "('Your Name. (2016)', 4.26548731265855, 125)\n",
      "('\"Day of the Doctor', 4.265227834698905, 135)\n",
      "('Ikiru (1952)', 4.24468859937177, 171)\n",
      "('Wallace & Gromit: The Best of Aardman Animation (1996)', 4.236078612191221, 1028)\n",
      "('\"Man Without a Past', 4.223398416159739, 124)\n",
      "('\"Black Cat', 4.211285402008407, 183)\n",
      "('Rashomon (Rashômon) (1950)', 4.183581262648332, 514)\n",
      "('Paradise Lost: The Child Murders at Robin Hood Hills (1996)', 4.1744493279042985, 188)\n",
      "('M (1931)', 4.174204271748266, 483)\n",
      "('Wild Tales (2014)', 4.170224553375334, 194)\n"
     ]
    }
   ],
   "source": [
    "# The format of each line is (userID, movieID, rating)\n",
    "\n",
    "# S3 - 10 movies you have watched with ratings 3 or higher. \n",
    "new_user_ratings = [\n",
    "     (0,260,3), # Star Wars (1977)\n",
    "     (0,1,4), # Toy Story (1995)\n",
    "     (0,356,5), # Forrest Gump (1994)\n",
    "     (0,2959,5), # Fight Club (1999)\n",
    "     (0,3033,1), # Spaceballs (1987)\n",
    "     (0,3100,2), # River Runs Through It\n",
    "     (0,3404,2), # Titanic (1953)\n",
    "     (0,3190,2), # Supernova (2000)\n",
    "     (0,54256,5), # Hot Rod (2007)\n",
    "     (0,3107,3) # Backdraft (1991)\n",
    "    ]\n",
    "\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print ('New user ratings: {}'.format(new_user_ratings_RDD.take(10)))\n",
    "\n",
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)\n",
    "\n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed,\n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print ('New model trained in {} seconds'.format(round(tt,3)))\n",
    "\n",
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "\n",
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)\n",
    "\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "\n",
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=100).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 25 reviews):\\n{}'.format('\\n'.join(map(str, top_movies))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persit Model for later use\n",
    "##### This could be later adjusted and or used for future web deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "\n",
    "model_path = os.path.join('/home/jovyan', 'models', 'movie_lens_als2')\n",
    "\n",
    "# Save and load model\n",
    "model.save(sc, model_path)\n",
    "same_model = MatrixFactorizationModel.load(sc, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
